{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Hero Video Processing - Google Colab\n",
    "\n",
    "This notebook processes tennis videos with player tracking (SAM-3d-body) and ball detection (SAM3) using a T4 GPU.\n",
    "\n",
    "**Make sure to:**\n",
    "1. Enable GPU: Runtime → Change runtime type → GPU (T4)\n",
    "2. Upload your video file\n",
    "3. Upload required model files (see instructions below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install core dependencies\n",
    "!pip install -q opencv-python numpy torch torchvision torchaudio tqdm pillow\n",
    "!pip install -q transformers accelerate\n",
    "!pip install -q git+https://github.com/facebookresearch/dinov2.git\n",
    "\n",
    "# Install additional dependencies for SAM-3d-body\n",
    "!pip install -q trimesh pyrender braceexpand\n",
    "\n",
    "# Install YOLO (ultralytics)\n",
    "!pip install -q ultralytics\n",
    "\n",
    "print(\"✅ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone_repos"
   },
   "source": [
    "## Step 2: Clone Required Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_sam3d"
   },
   "outputs": [],
   "source": [
    "# Clone SAM-3d-body repository\n",
    "!git clone -q https://github.com/facebookresearch/sam-3d-body.git\n",
    "\n",
    "# Clone SAM3 repository (adjust URL if different)\n",
    "# !git clone -q https://github.com/your-sam3-repo.git SAM3\n",
    "\n",
    "print(\"✅ Repositories cloned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_paths"
   },
   "source": [
    "## Step 3: Set Up Paths and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_imports"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import json\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "\n",
    "# Add SAM-3d-body to path (need both root and sam-3d-body subdirectory)\n",
    "sys.path.insert(0, '/content/sam-3d-body')\n",
    "sys.path.insert(0, '/content/sam-3d-body/sam-3d-body')\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('/content/output', exist_ok=True)\n",
    "\n",
    "print(\"✅ Paths and imports set up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_files"
   },
   "source": [
    "## Step 4: Upload Files\n",
    "\n",
    "**Upload your video file and model files here.**\n",
    "\n",
    "### Required Files:\n",
    "1. **Input video** (`.mp4` file)\n",
    "2. **SAM-3d-body model** (if not auto-downloaded)\n",
    "3. **SAM3 model** (if needed)\n",
    "4. **YOLO model** (optional, for human detection) - `playersnball5.pt`\n",
    "5. **Court detection model** (optional) - `model_tennis_court_det.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_video"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload video file\n",
    "print(\"Please upload your input video file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded video filename\n",
    "video_filename = list(uploaded.keys())[0]\n",
    "input_video_path = f\"/content/{video_filename}\"\n",
    "\n",
    "print(f\"✅ Video uploaded: {video_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_models"
   },
   "outputs": [],
   "source": [
    "# Upload model files (optional - some models auto-download)\n",
    "print(\"Upload model files (YOLO, court detection, etc.) or press Cancel to skip:\")\n",
    "model_files = files.upload()\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('/content/models', exist_ok=True)\n",
    "\n",
    "# Move uploaded models\n",
    "for filename in model_files.keys():\n",
    "    os.rename(f\"/content/{filename}\", f\"/content/models/{filename}\")\n",
    "    print(f\"✅ Model uploaded: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_models"
   },
   "source": [
    "## Step 5: Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_sam3d"
   },
   "outputs": [],
   "source": [
    "# Load SAM-3d-body model\n",
    "print(\"Loading SAM-3d-body model...\")\n",
    "\n",
    "try:\n",
    "    # Try using notebook utils (recommended)\n",
    "    from notebook.utils import setup_sam_3d_body, load_sam_3d_body_hf\n",
    "    from sam_3d_body.sam_3d_body_estimator import SAM3DBodyEstimator\n",
    "    from sam_3d_body.visualization.skeleton_visualizer import SkeletonVisualizer\n",
    "    from sam_3d_body.metadata.mhr70 import pose_info as mhr70_pose_info\n",
    "    \n",
    "    # Load model using notebook utils\n",
    "    model, model_cfg = load_sam_3d_body_hf(\"facebook/sam-3d-body-dinov3\", device=device)\n",
    "    \n",
    "    # Initialize estimator\n",
    "    estimator = SAM3DBodyEstimator(\n",
    "        sam_3d_body_model=model,\n",
    "        model_cfg=model_cfg,\n",
    "        human_detector=None,  # Will add YOLO later if available\n",
    "        human_segmentor=None,\n",
    "        fov_estimator=None,  # Optional\n",
    "    )\n",
    "    \n",
    "    print(\"✅ SAM-3d-body loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading SAM-3d-body: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    estimator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_sam3"
   },
   "outputs": [],
   "source": [
    "# Load SAM3 ball detector\n",
    "print(\"Loading SAM3 ball detector...\")\n",
    "\n",
    "ball_detector = None\n",
    "\n",
    "# Check if SAM3 directory exists\n",
    "sam3_paths = ['/content/SAM3', '/content/sam3', '/content/SAM-3']\n",
    "sam3_path = None\n",
    "for path in sam3_paths:\n",
    "    if os.path.exists(path):\n",
    "        sam3_path = path\n",
    "        break\n",
    "\n",
    "if sam3_path:\n",
    "    try:\n",
    "        # Add SAM3 to path\n",
    "        sys.path.insert(0, sam3_path)\n",
    "        \n",
    "        # Try importing SAM3BallDetector\n",
    "        from test_sam3_ball_detection import SAM3BallDetector\n",
    "        \n",
    "        # Initialize SAM3\n",
    "        ball_detector = SAM3BallDetector(\n",
    "            model_path=sam3_path,\n",
    "            device=device,\n",
    "            use_transformers=True\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ SAM3 ball detector loaded from {sam3_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading SAM3: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        ball_detector = None\n",
    "else:\n",
    "    print(\"⚠️ SAM3 directory not found. Please upload your SAM3 folder.\")\n",
    "    print(\"   Expected locations: /content/SAM3, /content/sam3, or /content/SAM-3\")\n",
    "    print(\"   You can upload it in the next cell or skip ball detection for now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_yolo"
   },
   "outputs": [],
   "source": [
    "# Load YOLO human detector (optional)\n",
    "yolo_detector = None\n",
    "yolo_model_path = \"/content/models/playersnball5.pt\"\n",
    "\n",
    "if os.path.exists(yolo_model_path):\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        yolo_model = YOLO(yolo_model_path)\n",
    "        yolo_model.to(device)  # Move to GPU if available\n",
    "        print(\"✅ YOLO detector loaded\")\n",
    "        yolo_detector = yolo_model\n",
    "        \n",
    "        # Update SAM-3d-body estimator with YOLO detector if available\n",
    "        if estimator is not None:\n",
    "            # Note: SAM3DBodyEstimator may need to be reinitialized with detector\n",
    "            # For now, YOLO will be used separately if needed\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not load YOLO: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"⚠️ YOLO model not found at /content/models/playersnball5.pt\")\n",
    "    print(\"   Skipping human detection (SAM-3d-body will process full image)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "processing_config"
   },
   "source": [
    "## Step 6: Configure Processing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Processing configuration\n",
    "config = {\n",
    "    'frame_skip': 5,  # Process every 5th frame (1 = all frames, higher = faster)\n",
    "    'fps': 30.0,  # Output video FPS\n",
    "    'player_color': '#50C878',  # Emerald green\n",
    "    'ball_color': '#50C878',  # Emerald green\n",
    "    'trail_length': 30,  # Ball trajectory trail length\n",
    "    'keypoints_only': False,  # False = full mesh, True = keypoints only (faster)\n",
    "    'process_resolution': 720,  # Downscale to 720px width for processing (0 = original)\n",
    "    'enable_court_detection': False,  # Enable if you have court model\n",
    "    'use_ensemble_ball': False,  # Use ensemble ball detection (slower but more accurate)\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "process_video"
   },
   "source": [
    "## Step 7: Process Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "process_main"
   },
   "outputs": [],
   "source": [
    "def hex_to_bgr(hex_color: str) -> Tuple[int, int, int]:\n",
    "    \"\"\"Convert hex color to BGR tuple for OpenCV.\"\"\"\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    return (b, g, r)  # BGR format\n",
    "\n",
    "\n",
    "def process_video_colab(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    config: dict\n",
    "):\n",
    "    \"\"\"Process video with player tracking and ball detection.\"\"\"\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video: {input_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"\\nVideo Properties:\")\n",
    "    print(f\"  Resolution: {width}x{height}\")\n",
    "    print(f\"  FPS: {original_fps:.2f}\")\n",
    "    print(f\"  Total frames: {total_frames}\")\n",
    "    \n",
    "    # Calculate processing parameters\n",
    "    frame_skip = config['frame_skip']\n",
    "    frames_to_process = (total_frames + frame_skip - 1) // frame_skip\n",
    "    \n",
    "    # Resolution scaling\n",
    "    process_resolution = config.get('process_resolution', 0)\n",
    "    if process_resolution > 0 and process_resolution < width:\n",
    "        scale_factor = process_resolution / width\n",
    "        process_width = process_resolution\n",
    "        process_height = int(height * scale_factor)\n",
    "        print(f\"  Processing at: {process_width}x{process_height} (scale: {scale_factor:.2f})\")\n",
    "    else:\n",
    "        scale_factor = 1.0\n",
    "        process_width = width\n",
    "        process_height = height\n",
    "    \n",
    "    print(f\"\\nProcessing:\")\n",
    "    print(f\"  Frame skip: {frame_skip} (processing {frames_to_process} frames)\")\n",
    "    print(f\"  Output FPS: {config['fps']:.2f}\")\n",
    "    \n",
    "    # Setup output video\n",
    "    output_width = width\n",
    "    output_height = height\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_fps = original_fps  # Keep original FPS\n",
    "    out = cv2.VideoWriter(output_path, fourcc, output_fps, (output_width, output_height))\n",
    "    \n",
    "    # Initialize skeleton visualizer if needed\n",
    "    skeleton_visualizer = None\n",
    "    if config['keypoints_only']:\n",
    "        try:\n",
    "            skeleton_visualizer = SkeletonVisualizer(line_width=2, radius=5)\n",
    "            skeleton_visualizer.set_pose_meta(mhr70_pose_info)\n",
    "            # Set emerald green color\n",
    "            emerald_green = (80, 200, 120)  # RGB\n",
    "            skeleton_visualizer.kpt_color = emerald_green\n",
    "            skeleton_visualizer.link_color = emerald_green\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Color conversion\n",
    "    player_color_bgr = hex_to_bgr(config['player_color'])\n",
    "    ball_color_bgr = hex_to_bgr(config['ball_color'])\n",
    "    \n",
    "    # Processing loop\n",
    "    frame_count = 0\n",
    "    processed_count = 0\n",
    "    ball_trajectory = []\n",
    "    \n",
    "    print(f\"\\nStarting processing...\")\n",
    "    \n",
    "    with tqdm(total=frames_to_process, desc=\"Processing\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Skip frames if needed\n",
    "            if frame_count % frame_skip != 0:\n",
    "                frame_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Downscale for processing if needed\n",
    "            if scale_factor < 1.0:\n",
    "                frame_processed = cv2.resize(frame, (process_width, process_height), interpolation=cv2.INTER_AREA)\n",
    "            else:\n",
    "                frame_processed = frame.copy()\n",
    "            \n",
    "            # Convert BGR to RGB for models\n",
    "            frame_rgb = cv2.cvtColor(frame_processed, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Process with SAM-3d-body\n",
    "            player_outputs = []\n",
    "            if estimator:\n",
    "                try:\n",
    "                    inference_type = \"keypoints_only\" if config['keypoints_only'] else \"full\"\n",
    "                    player_outputs = estimator.process_one_image(frame_rgb, inference_type=inference_type)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nWarning: SAM-3d-body failed on frame {frame_count}: {e}\")\n",
    "            \n",
    "            # Process with ball detector\n",
    "            ball_detection = None\n",
    "            if ball_detector:\n",
    "                try:\n",
    "                    ball_detection = ball_detector.detect_ball(frame_processed, text_prompt=\"tennis ball\")\n",
    "                except Exception as e:\n",
    "                    pass  # Silently fail\n",
    "            \n",
    "            # Update ball trajectory\n",
    "            if ball_detection:\n",
    "                center, confidence, mask = ball_detection\n",
    "                # Scale center back to original resolution if needed\n",
    "                if scale_factor < 1.0:\n",
    "                    center = (int(center[0] / scale_factor), int(center[1] / scale_factor))\n",
    "                ball_trajectory.append(center)\n",
    "                if len(ball_trajectory) > config['trail_length']:\n",
    "                    ball_trajectory.pop(0)\n",
    "            else:\n",
    "                if len(ball_trajectory) > 0:\n",
    "                    ball_trajectory.pop(0)\n",
    "            \n",
    "            # Create visualization\n",
    "            vis_frame = frame.copy()\n",
    "            \n",
    "            # Draw ball trajectory\n",
    "            if len(ball_trajectory) > 1:\n",
    "                for i in range(len(ball_trajectory) - 1):\n",
    "                    pt1 = ball_trajectory[i]\n",
    "                    pt2 = ball_trajectory[i + 1]\n",
    "                    alpha = (i + 1) / len(ball_trajectory)\n",
    "                    color = tuple(int(c * alpha) for c in ball_color_bgr)\n",
    "                    thickness = max(1, int(2 * alpha))\n",
    "                    cv2.line(vis_frame, pt1, pt2, color, thickness, cv2.LINE_AA)\n",
    "            \n",
    "            # Draw players\n",
    "            if player_outputs:\n",
    "                if config['keypoints_only'] and skeleton_visualizer:\n",
    "                    # Keypoints-only mode\n",
    "                    for output in player_outputs:\n",
    "                        keypoints_2d = output.get(\"pred_keypoints_2d\", None)\n",
    "                        if keypoints_2d is not None:\n",
    "                            keypoints_2d_with_vis = np.concatenate(\n",
    "                                [keypoints_2d, np.ones((keypoints_2d.shape[0], 1))], axis=-1\n",
    "                            )\n",
    "                            vis_frame_rgb = cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB)\n",
    "                            vis_frame_rgb = skeleton_visualizer.draw_skeleton(\n",
    "                                vis_frame_rgb, keypoints_2d_with_vis, kpt_thr=0.3\n",
    "                            )\n",
    "                            vis_frame = cv2.cvtColor(vis_frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "                else:\n",
    "                    # Full mesh mode (simplified - just draw keypoints for now)\n",
    "                    for output in player_outputs:\n",
    "                        keypoints_2d = output.get(\"pred_keypoints_2d\", None)\n",
    "                        if keypoints_2d is not None:\n",
    "                            # Draw simple skeleton\n",
    "                            for kp in keypoints_2d:\n",
    "                                if len(kp) > 2 and kp[2] > 0:\n",
    "                                    x, y = int(kp[0] / scale_factor) if scale_factor < 1.0 else int(kp[0]), \\\n",
    "                                           int(kp[1] / scale_factor) if scale_factor < 1.0 else int(kp[1])\n",
    "                                    cv2.circle(vis_frame, (x, y), 4, player_color_bgr, -1)\n",
    "            \n",
    "            # Draw ball\n",
    "            if ball_detection:\n",
    "                center, confidence, mask = ball_detection\n",
    "                if scale_factor < 1.0:\n",
    "                    center = (int(center[0] / scale_factor), int(center[1] / scale_factor))\n",
    "                cv2.circle(vis_frame, center, 8, ball_color_bgr, -1)\n",
    "                cv2.circle(vis_frame, center, 8, (255, 255, 255), 2)\n",
    "            \n",
    "            # Write frame multiple times to maintain original playback speed\n",
    "            for _ in range(frame_skip):\n",
    "                out.write(vis_frame)\n",
    "            \n",
    "            processed_count += 1\n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"\\n✅ Processing complete!\")\n",
    "    print(f\"Processed {processed_count} frames\")\n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "\n",
    "\n",
    "# Process the video\n",
    "output_video_path = \"/content/output/hero_video_processed.mp4\"\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "process_video_colab(input_video_path, output_video_path, config)\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n⏱️ Total processing time: {processing_time / 60:.2f} minutes ({processing_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## Step 8: Download Output Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_output"
   },
   "outputs": [],
   "source": [
    "# Download the processed video\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading processed video...\")\n",
    "files.download(output_video_path)\n",
    "print(\"✅ Download complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
