{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Hero Video Processing - Google Colab\n",
        "\n",
        "This notebook processes tennis videos with player tracking (SAM-3d-body) and ball detection (SAM3).\n",
        "\n",
        "**Setup:**\n",
        "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU (T4 or A100)\n",
        "   - T4: Good for keypoints-only mode or lower resolution\n",
        "   - A100: Recommended for full mesh rendering at higher resolutions\n",
        "2. Make sure your folders are in `/content/drive/MyDrive/CourtVision/`:\n",
        "   - SAM-3d-body/\n",
        "   - SAM3/\n",
        "   - models/\n",
        "   - hero-video/ (with your raw video file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Set CUDA memory allocation config to reduce fragmentation (MUST be before torch import)\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "print(\"‚úÖ Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True (helps prevent OOM errors)\")\n",
        "\n",
        "# Install core dependencies\n",
        "!pip install -q opencv-python numpy torch torchvision torchaudio tqdm pillow\n",
        "!pip install -q transformers accelerate\n",
        "\n",
        "# Upgrade transformers to 5.0+ (required for SAM3)\n",
        "!pip install --upgrade -q git+https://github.com/huggingface/transformers\n",
        "!pip install -q git+https://github.com/facebookresearch/dinov2.git\n",
        "\n",
        "# Install ALL SAM-3d-body dependencies (complete list from official INSTALL.md)\n",
        "!pip install -q pytorch-lightning pyrender opencv-python yacs scikit-image einops timm dill pandas rich\n",
        "!pip install -q hydra-core hydra-submitit-launcher hydra-colorlog pyrootutils webdataset chump\n",
        "!pip install -q \"networkx==3.2.1\" roma joblib seaborn wandb appdirs appnope\n",
        "!pip install -q ffmpeg cython jsonlines pytest xtcocotools loguru optree fvcore\n",
        "!pip install -q black pycocotools tensorboard huggingface_hub\n",
        "!pip install -q trimesh braceexpand\n",
        "\n",
        "# Install Detectron2 (optional but recommended for human detection)\n",
        "!pip install -q 'git+https://github.com/facebookresearch/detectron2.git@a1ce2f9' --no-build-isolation --no-deps\n",
        "\n",
        "# Install MoGe (required for FOV estimation)\n",
        "!pip install -q git+https://github.com/microsoft/MoGe.git\n",
        "\n",
        "# Install YOLO (ultralytics)\n",
        "!pip install -q ultralytics\n",
        "\n",
        "print(\"‚úÖ All dependencies installed (including roma and all SAM-3d-body requirements)\")\n",
        "\n",
        "# Verify critical dependencies\n",
        "print(\"\\nVerifying critical dependencies...\")\n",
        "try:\n",
        "    import roma\n",
        "    print(\"‚úÖ roma installed\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå roma NOT installed - this will cause errors!\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"‚úÖ PyTorch {torch.__version__} installed\")\n",
        "    print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå PyTorch NOT installed\")\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "    print(f\"‚úÖ OpenCV {cv2.__version__} installed\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå OpenCV NOT installed\")\n",
        "\n",
        "try:\n",
        "    import transformers\n",
        "    print(f\"‚úÖ Transformers {transformers.__version__} installed\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå Transformers NOT installed\")\n",
        "\n",
        "print(\"\\n‚úÖ Dependency verification complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## Step 2: Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"üìÇ Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n‚úÖ Google Drive mounted!\")\n",
        "print(\"   Your folders should be at: /content/drive/MyDrive/CourtVision/\")\n",
        "\n",
        "# Check what folders are available\n",
        "import os\n",
        "courtvision_path = '/content/drive/MyDrive/CourtVision'\n",
        "if os.path.exists(courtvision_path):\n",
        "    print(f\"\\nüìÅ Folders found in {courtvision_path}:\")\n",
        "    for item in os.listdir(courtvision_path):\n",
        "        item_path = os.path.join(courtvision_path, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"   ‚úÖ {item}/\")\n",
        "        else:\n",
        "            print(f\"   üìÑ {item}\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è Path {courtvision_path} not found.\")\n",
        "    print(\"   Make sure your folders are in /CourtVision/ on your Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "## Step 3: Set Up Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_paths"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import json\n",
        "from typing import List, Optional, Tuple, Dict, Any\n",
        "\n",
        "# Set up Google Drive paths\n",
        "drive_base = '/content/drive/MyDrive/CourtVision'\n",
        "\n",
        "# Add SAM-3d-body to path\n",
        "sam3d_path = f\"{drive_base}/SAM-3d-body\"\n",
        "if os.path.exists(f\"{sam3d_path}/sam-3d-body\"):\n",
        "    sys.path.insert(0, f\"{sam3d_path}/sam-3d-body\")\n",
        "sys.path.insert(0, sam3d_path)\n",
        "\n",
        "# Add hero-video to path\n",
        "hero_video_path = f\"{drive_base}/hero-video\"\n",
        "sys.path.insert(0, hero_video_path)\n",
        "sys.path.insert(0, drive_base)\n",
        "\n",
        "# Check GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('/content/output', exist_ok=True)\n",
        "\n",
        "# Check GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    free = total - reserved\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    \n",
        "    print(f\"   GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved, {free:.2f} GB free, {total:.2f} GB total\")\n",
        "    \n",
        "    if \"A100\" in gpu_name:\n",
        "        print(f\"   ‚úÖ A100 detected! You have plenty of memory ({free:.2f} GB free).\")\n",
        "        print(f\"   üí° Consider using higher quality settings:\")\n",
        "        print(f\"      - Higher process_resolution (e.g., 1080 or 1280 instead of 720)\")\n",
        "        print(f\"      - Enable ensemble ball detection for better accuracy\")\n",
        "        print(f\"      - Process every frame (frame_skip=1) for smoother output\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('/content/output', exist_ok=True)\n",
        "\n",
        "print(\"\\n‚úÖ Paths configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "## Step 4: Find Video File\n",
        "\n",
        "The raw video should be in your `hero-video` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "find_video"
      },
      "outputs": [],
      "source": [
        "# Find video file in hero-video folder\n",
        "# Ensure paths are defined\n",
        "drive_base = '/content/drive/MyDrive/CourtVision'\n",
        "hero_video_path = f\"{drive_base}/hero-video\"\n",
        "\n",
        "video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.MP4', '.AVI', '.MOV', '.MKV']\n",
        "input_video_path = None\n",
        "\n",
        "if not os.path.exists(hero_video_path):\n",
        "    print(f\"‚ùå hero-video folder not found: {hero_video_path}\")\n",
        "else:\n",
        "    print(f\"üìÅ Searching for video in: {hero_video_path}\")\n",
        "    for file in os.listdir(hero_video_path):\n",
        "        file_path = os.path.join(hero_video_path, file)\n",
        "        # Skip directories and the processing script\n",
        "        if os.path.isdir(file_path) or file == 'process_hero_video.py':\n",
        "            continue\n",
        "        if any(file.endswith(ext) for ext in video_extensions):\n",
        "            input_video_path = file_path\n",
        "            print(f\"‚úÖ Found video: {file}\")\n",
        "            print(f\"   Path: {input_video_path}\")\n",
        "            break\n",
        "\n",
        "    if not input_video_path:\n",
        "        print(\"‚ùå No video file found in hero-video folder!\")\n",
        "        print(f\"   Make sure your raw video file is in: {hero_video_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4.5"
      },
      "source": [
        "## Step 4.5: Authenticate with Hugging Face (Required for SAM-3d-body)\n",
        "\n",
        "**The SAM-3d-body model requires Hugging Face authentication.**\n",
        "\n",
        "1. Go to https://huggingface.co/facebook/sam-3d-body-dinov3\n",
        "2. Click \"Agree and access repository\" (request access if needed)\n",
        "3. Go to https://huggingface.co/settings/tokens\n",
        "4. Create a token (read access is enough)\n",
        "5. Run the cell below and paste your token when prompted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auth_hf"
      },
      "outputs": [],
      "source": [
        "# Authenticate with Hugging Face\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "print(\"üîê Hugging Face Authentication\")\n",
        "\n",
        "# Check if token is already set in environment\n",
        "if 'HF_TOKEN' in os.environ:\n",
        "    print(\"‚úÖ Found HF_TOKEN in environment variables\")\n",
        "    print(\"‚úÖ Authenticated with Hugging Face!\")\n",
        "else:\n",
        "    print(\"\\nPlease paste your Hugging Face token below.\")\n",
        "    print(\"Get your token from: https://huggingface.co/settings/tokens\")\n",
        "    print(\"\\nüí° Tip: If you have a token file, you can also set it manually:\")\n",
        "    print(\"  import os\")\n",
        "    print(\"  os.environ['HF_TOKEN'] = 'your_token_here'\")\n",
        "    print(\"  from huggingface_hub import login\")\n",
        "    print(\"  login()\")\n",
        "    print(\"\\n---\")\n",
        "    \n",
        "    # Login (will prompt for token)\n",
        "    try:\n",
        "        login()\n",
        "        print(\"\\n‚úÖ Authenticated with Hugging Face!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Authentication failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5"
      },
      "source": [
        "## Step 5: Load Models\n",
        "\n",
        "This step loads:\n",
        "- SAM-3d-body (player tracking)\n",
        "- SAM3 (ball detection)\n",
        "- YOLO human detector (for multi-person detection)\n",
        "- Court detector (if model available)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_models"
      },
      "outputs": [],
      "source": [
        "# Ensure paths are defined\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Check GPU availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(f\"Using device: {device} (CPU mode - will be slow)\")\n",
        "\n",
        "drive_base = '/content/drive/MyDrive/CourtVision'\n",
        "sam3d_path = f\"{drive_base}/SAM-3d-body\"\n",
        "hero_video_path = f\"{drive_base}/hero-video\"\n",
        "\n",
        "# Add SAM-3d-body paths to sys.path (if not already added)\n",
        "sam3d_body_path = f\"{sam3d_path}/sam-3d-body\"\n",
        "if sam3d_body_path not in sys.path:\n",
        "    sys.path.insert(0, sam3d_body_path)\n",
        "if sam3d_path not in sys.path:\n",
        "    sys.path.insert(0, sam3d_path)\n",
        "if hero_video_path not in sys.path:\n",
        "    sys.path.insert(0, hero_video_path)\n",
        "\n",
        "# Load SAM-3d-body\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Loading SAM-3d-body model...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if authenticated with Hugging Face\n",
        "try:\n",
        "    from huggingface_hub import whoami\n",
        "    user_info = whoami()\n",
        "    print(f\"   ‚úÖ Authenticated as: {user_info.get('name', 'user')}\")\n",
        "except Exception:\n",
        "    print(\"   ‚ö†Ô∏è Not authenticated with Hugging Face\")\n",
        "    print(\"   Please run Step 4.5 to authenticate first\")\n",
        "    raise ImportError(\"Hugging Face authentication required\")\n",
        "\n",
        "# First, set up human detector for multi-person detection (BEFORE loading SAM-3d-body)\n",
        "human_detector = None\n",
        "yolo_model_path = f\"{drive_base}/models/player/playersnball5.pt\"\n",
        "print(f\"\\n1. Setting up YOLO human detector for multi-person detection...\")\n",
        "print(f\"   Looking for YOLO model at: {yolo_model_path}\")\n",
        "print(f\"   File exists: {os.path.exists(yolo_model_path)}\")\n",
        "\n",
        "if os.path.exists(yolo_model_path):\n",
        "    try:\n",
        "        # Import YOLO human detector wrapper\n",
        "        from yolo_human_detector import YOLOHumanDetector\n",
        "        print(f\"   Creating YOLOHumanDetector...\")\n",
        "        human_detector = YOLOHumanDetector(model_path=Path(yolo_model_path), device=device)\n",
        "        print(\"   ‚úÖ YOLO human detector loaded (for multi-person detection)\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Could not load YOLO human detector: {e}\")\n",
        "        print(\"   Will process full image as single person (only 1 player will be detected)\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        human_detector = None\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è YOLO model not found at: {yolo_model_path}\")\n",
        "    print(\"   Will process full image as single person (only 1 player will be detected)\")\n",
        "    print(\"   To enable multi-person detection, place playersnball5.pt in models/player/\")\n",
        "    # Also check alternative locations\n",
        "    alt_paths = [\n",
        "        f\"{drive_base}/old/models/player/playersnball5.pt\",\n",
        "    ]\n",
        "    for alt_path in alt_paths:\n",
        "        if os.path.exists(alt_path):\n",
        "            print(f\"   Found YOLO model at alternative location: {alt_path}\")\n",
        "            print(f\"   Please copy it to: {yolo_model_path}\")\n",
        "            break\n",
        "    human_detector = None\n",
        "\n",
        "# Try to load FOV estimator (improves camera calibration and mesh alignment)\n",
        "fov_estimator = None\n",
        "print(f\"\\n2. Setting up FOV estimator (improves mesh alignment)...\")\n",
        "try:\n",
        "    from tools.build_fov_estimator import FOVEstimator\n",
        "    fov_estimator = FOVEstimator(name=\"moge2\", device=device)\n",
        "    print(\"   ‚úÖ FOV estimator loaded\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ö†Ô∏è FOV estimator not available: {e}\")\n",
        "    fov_estimator = None\n",
        "\n",
        "# Load SAM-3d-body model\n",
        "print(f\"\\n3. Loading SAM-3d-body model...\")\n",
        "try:\n",
        "    # Import from SAM-3d-body package directly\n",
        "    from sam_3d_body import load_sam_3d_body_hf\n",
        "    from sam_3d_body.sam_3d_body_estimator import SAM3DBodyEstimator\n",
        "    from sam_3d_body.visualization.skeleton_visualizer import SkeletonVisualizer\n",
        "    from sam_3d_body.metadata.mhr70 import pose_info as mhr70_pose_info\n",
        "    \n",
        "    model, model_cfg = load_sam_3d_body_hf(\"facebook/sam-3d-body-dinov3\", device=device)\n",
        "    estimator = SAM3DBodyEstimator(\n",
        "        sam_3d_body_model=model,\n",
        "        model_cfg=model_cfg,\n",
        "        human_detector=human_detector,  # Pass the human detector for multi-person detection!\n",
        "        human_segmentor=None,\n",
        "        fov_estimator=fov_estimator,  # Pass FOV estimator for better mesh alignment\n",
        "    )\n",
        "    skeleton_visualizer = SkeletonVisualizer(mhr70_pose_info)\n",
        "    if human_detector:\n",
        "        print(\"   ‚úÖ SAM-3d-body loaded with YOLO human detector (multi-person detection enabled)\")\n",
        "    else:\n",
        "        print(\"   ‚úÖ SAM-3d-body loaded (without human detector - will process full image as single person)\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Error loading SAM-3d-body: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    estimator = None\n",
        "\n",
        "# Load SAM3 ball detector\n",
        "print(f\"\\n4. Loading SAM3 ball detector...\")\n",
        "try:\n",
        "    sam3_path = f\"{drive_base}/SAM3\"\n",
        "    if sam3_path not in sys.path:\n",
        "        sys.path.insert(0, sam3_path)\n",
        "    \n",
        "    # Check transformers version first\n",
        "    import transformers\n",
        "    transformers_version = transformers.__version__.split(\".\")[0]\n",
        "    if int(transformers_version) < 5:\n",
        "        print(f\"   ‚ö†Ô∏è Transformers version {transformers.__version__} is too old (need 5.0+)\")\n",
        "        print(\"   Upgrading transformers (this may take a few minutes)...\")\n",
        "        import subprocess\n",
        "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"git+https://github.com/huggingface/transformers\"], \n",
        "                                capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(\"   ‚úÖ Transformers upgraded! Please restart runtime (Runtime ‚Üí Restart runtime) and run this cell again.\")\n",
        "            raise ImportError(\"Transformers upgraded - restart runtime\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå Failed to upgrade transformers: {result.stderr}\")\n",
        "            raise ImportError(\"Could not upgrade transformers\")\n",
        "    \n",
        "    from test_sam3_ball_detection import SAM3BallDetector\n",
        "    ball_detector = SAM3BallDetector(model_path=sam3_path, device=device, use_transformers=True)\n",
        "    print(\"   ‚úÖ SAM3 ball detector loaded\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Error loading SAM3: {e}\")\n",
        "    print(\"   Note: SAM3 requires transformers 5.0+. If upgrade was attempted, restart runtime.\")\n",
        "    ball_detector = None\n",
        "\n",
        "# Initialize court detector (try to load if model exists)\n",
        "court_detector = None\n",
        "print(f\"\\n5. Setting up court detector...\")\n",
        "try:\n",
        "    # Try importing court detector - add multiple possible paths\n",
        "    court_paths = [\n",
        "        (f\"{drive_base}/old/scripts/legacy/demos\", 'court_demo'),\n",
        "        (f\"{drive_base}/old/src/core\", 'tennis_CV'),\n",
        "    ]\n",
        "    CourtDetector = None\n",
        "    for court_path, module_name in court_paths:\n",
        "        print(f\"   Checking: {court_path}\")\n",
        "        if not os.path.exists(court_path):\n",
        "            print(f\"     ‚úó Path does not exist\")\n",
        "            continue\n",
        "        \n",
        "        # Check if the module file exists\n",
        "        module_file = f\"{court_path}/{module_name}.py\"\n",
        "        if not os.path.exists(module_file):\n",
        "            print(f\"     ‚úó Module file not found: {module_file}\")\n",
        "            continue\n",
        "        \n",
        "        if court_path not in sys.path:\n",
        "            sys.path.insert(0, court_path)\n",
        "        try:\n",
        "            if module_name == 'court_demo':\n",
        "                from court_demo import CourtDetector\n",
        "            else:\n",
        "                from tennis_CV import CourtDetector\n",
        "            print(f\"   ‚úÖ Imported CourtDetector from: {court_path}\")\n",
        "            break\n",
        "        except ImportError as import_err:\n",
        "            print(f\"     ‚úó Import failed: {import_err}\")\n",
        "            continue\n",
        "    \n",
        "    if CourtDetector is None:\n",
        "        print(f\"   ‚ö†Ô∏è Could not import CourtDetector from any location\")\n",
        "        print(f\"   Court detection will be disabled\")\n",
        "        raise ImportError(\"CourtDetector not available\")\n",
        "    \n",
        "    # Find court model\n",
        "    court_model_path = None\n",
        "    possible_paths = [\n",
        "        f\"{drive_base}/models/court/model_tennis_court_det.pt\",\n",
        "        f\"{drive_base}/old/models/court/model_tennis_court_det.pt\",\n",
        "    ]\n",
        "    \n",
        "    print(f\"   Searching for court model 'model_tennis_court_det.pt'...\")\n",
        "    for path in possible_paths:\n",
        "        exists = os.path.exists(path)\n",
        "        print(f\"     {'‚úì' if exists else '‚úó'} {path}\")\n",
        "        if exists:\n",
        "            court_model_path = path\n",
        "            print(f\"   ‚úÖ Found court model at: {court_model_path}\")\n",
        "            break\n",
        "    \n",
        "    if court_model_path:\n",
        "        court_config = {\n",
        "            'input_width': 640,\n",
        "            'input_height': 360,\n",
        "            'low_threshold': 170,\n",
        "            'min_radius': 10,\n",
        "            'max_radius': 25,\n",
        "            'use_refine_kps': True,\n",
        "            'use_homography': True\n",
        "        }\n",
        "        court_detector = CourtDetector(model_path=court_model_path, config=court_config)\n",
        "        if court_detector.model is not None:\n",
        "            print(\"   ‚úÖ Court detector ready\")\n",
        "        else:\n",
        "            print(\"   ‚ö†Ô∏è Court detector model failed to load\")\n",
        "            court_detector = None\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è Court model not found. Searched in:\")\n",
        "        for path in possible_paths:\n",
        "            print(f\"     {'‚úì' if os.path.exists(path) else '‚úó'} {path}\")\n",
        "        court_detector = None\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ö†Ô∏è Court detector initialization failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    court_detector = None\n",
        "\n",
        "if court_detector is None:\n",
        "    print(\"   Court detector not available (will skip court detection)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ All models loaded!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6"
      },
      "source": [
        "## Step 6: Configure Processing\n",
        "\n",
        "Adjust these parameters as needed:\n",
        "- `frame_skip`: Process every Nth frame (1 = all frames, higher = faster)\n",
        "- `process_resolution`: Downscale to this width for processing (0 = original, 720/1080 = faster)\n",
        "- `keypoints_only`: False = full 3D mesh (slow but best quality), True = skeleton only (fast)\n",
        "- `enable_court_detection`: Enable court line detection (requires court model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "# Processing configuration\n",
        "# With A100 GPU (40GB), you can use higher quality settings:\n",
        "config = {\n",
        "    'frame_skip': 1,  # Process every frame (1 = all frames, higher = faster)\n",
        "    'fps': 30.0,  # Output video FPS\n",
        "    'player_color': '#50C878',  # Emerald green\n",
        "    'ball_color': '#50C878',  # Emerald green\n",
        "    'trail_length': 30,  # Ball trajectory trail length\n",
        "    'keypoints_only': False,  # False = full mesh, True = keypoints only (faster)\n",
        "    'process_resolution': 1080,  # A100 can handle 1080p! (720 = faster, 1080 = better quality, 0 = original)\n",
        "    'enable_court_detection': True,  # Enable court detection (requires court model in models/court/)\n",
        "    'use_ensemble_ball': False,  # Set to True for better ball detection (uses more memory but A100 can handle it)\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6.5"
      },
      "source": [
        "## Step 6.5: Test Single Frame (Preview)\n",
        "\n",
        "**Run this before processing the full video!**\n",
        "\n",
        "Process and display a single frame to verify everything looks good:\n",
        "- Players are detected correctly\n",
        "- Mesh aligns with players\n",
        "- Ball detection works\n",
        "- Court detection works (if enabled)\n",
        "\n",
        "If everything looks good, proceed to Step 7 to process the full video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_single_frame"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Ensure paths are defined\n",
        "drive_base = '/content/drive/MyDrive/CourtVision'\n",
        "hero_video_path = f\"{drive_base}/hero-video\"\n",
        "\n",
        "# Add paths to sys.path\n",
        "sys.path.insert(0, str(Path(hero_video_path).resolve()))\n",
        "sys.path.insert(0, str(Path(f\"{drive_base}/SAM-3d-body/sam-3d-body\").resolve()))\n",
        "\n",
        "# Check that required variables exist\n",
        "if 'input_video_path' not in globals() or input_video_path is None:\n",
        "    print(\"‚ùå Error: Video file not found. Please run Step 4 first.\")\n",
        "elif 'config' not in globals():\n",
        "    print(\"‚ùå Error: Configuration not set. Please run Step 6 first.\")\n",
        "elif 'estimator' not in globals() or estimator is None:\n",
        "    print(\"‚ùå Error: Models not initialized. Please run Step 5 first.\")\n",
        "else:\n",
        "    print(\"‚úÖ All prerequisites met. Processing single frame...\\n\")\n",
        "    \n",
        "    # Frame to test (adjust if needed - use a frame with visible player/ball)\n",
        "    test_frame_number = 20  # Change this to test different frames\n",
        "    \n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"‚ùå Error: Could not open video: {input_video_path}\")\n",
        "    else:\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        print(f\"üìπ Video opened: {total_frames} total frames\")\n",
        "        print(f\"üéØ Testing frame {test_frame_number} (0-indexed: {test_frame_number-1})\\n\")\n",
        "        \n",
        "        # Seek to frame\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, test_frame_number - 1)\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        if not ret:\n",
        "            print(f\"‚ùå Error: Could not read frame {test_frame_number}\")\n",
        "        else:\n",
        "            print(f\"‚úÖ Frame {test_frame_number} loaded: {frame.shape}\")\n",
        "            \n",
        "            # Apply same processing as main script\n",
        "            process_resolution = config.get('process_resolution', 720)\n",
        "            original_height, original_width = frame.shape[:2]\n",
        "            \n",
        "            # Calculate scale factor\n",
        "            if process_resolution > 0:\n",
        "                scale_factor = process_resolution / original_width\n",
        "                process_width = process_resolution\n",
        "                process_height = int(original_height * scale_factor)\n",
        "            else:\n",
        "                scale_factor = 1.0\n",
        "                process_width = original_width\n",
        "                process_height = original_height\n",
        "            \n",
        "            # Downscale if needed\n",
        "            if scale_factor < 1.0:\n",
        "                print(f\"üìê Downscaling from {original_width}x{original_height} to {process_width}x{process_height}\")\n",
        "                frame = cv2.resize(frame, (process_width, process_height), interpolation=cv2.INTER_AREA)\n",
        "            \n",
        "            # Convert BGR to RGB for SAM-3d-body\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # Process with SAM-3d-body\n",
        "            print(\"ü§ñ Running SAM-3d-body...\")\n",
        "            keypoints_only = config.get('keypoints_only', False)\n",
        "            # Check if detector is being used\n",
        "            if hasattr(estimator, 'detector') and estimator.detector is not None:\n",
        "                print(f\"   ‚úÖ Using human detector: {type(estimator.detector).__name__}\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è No human detector - will process full image as single person\")\n",
        "            # Use lower thresholds for better multi-person detection\n",
        "            outputs = estimator.process_one_image(\n",
        "                frame_rgb,\n",
        "                inference_type=\"full\" if not keypoints_only else \"keypoints_only\",\n",
        "                bbox_thr=0.15,  # Even lower threshold to detect more people\n",
        "                nms_thr=0.5,   # Higher NMS to keep separate people\n",
        "            )\n",
        "            print(f\"‚úÖ SAM-3d-body: {len(outputs)} person(s) detected\")\n",
        "            \n",
        "            # Process with ball detector\n",
        "            print(\"‚öΩ Running ball detection...\")\n",
        "            ball_prompt = \"tennis ball\"\n",
        "            ball_detection = None\n",
        "            try:\n",
        "                if hasattr(ball_detector, 'detect_ball'):\n",
        "                    import inspect\n",
        "                    sig = inspect.signature(ball_detector.detect_ball)\n",
        "                    if 'threshold' in sig.parameters:\n",
        "                        ball_detection = ball_detector.detect_ball(\n",
        "                            frame,\n",
        "                            text_prompt=ball_prompt,\n",
        "                            threshold=0.3\n",
        "                        )\n",
        "                    else:\n",
        "                        ball_detection = ball_detector.detect_ball(frame, text_prompt=ball_prompt)\n",
        "                    \n",
        "                    if ball_detection:\n",
        "                        center, conf, mask = ball_detection\n",
        "                        print(f\"‚úÖ Ball detected at {center} (confidence: {conf:.2f})\")\n",
        "                    else:\n",
        "                        print(\"‚ö†Ô∏è No ball detected\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Ball detection error: {e}\")\n",
        "            \n",
        "            # Create visualization\n",
        "            print(\"üé® Creating visualization...\")\n",
        "            from visualizer import HeroVideoVisualizer\n",
        "            \n",
        "            # Convert hex colors to BGR tuples (OpenCV format)\n",
        "            def hex_to_bgr(hex_color: str):\n",
        "                \"\"\"Convert hex color to BGR tuple for OpenCV.\"\"\"\n",
        "                hex_color = hex_color.lstrip('#')\n",
        "                r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
        "                return (b, g, r)  # BGR format\n",
        "            \n",
        "            player_color_bgr = hex_to_bgr(config['player_color'])\n",
        "            ball_color_bgr = hex_to_bgr(config['ball_color'])\n",
        "            \n",
        "            visualizer = HeroVideoVisualizer(\n",
        "                player_color=player_color_bgr,\n",
        "                ball_color=ball_color_bgr,\n",
        "                trail_length=config['trail_length']\n",
        "            )\n",
        "            \n",
        "            # Simple ball trajectory for preview (just current detection)\n",
        "            ball_trajectory = []\n",
        "            if ball_detection:\n",
        "                center, _, _ = ball_detection\n",
        "                ball_trajectory = [center]  # Just show current position\n",
        "            \n",
        "            # Try court detection if available\n",
        "            court_keypoints = None\n",
        "            if config.get('enable_court_detection', False):\n",
        "                try:\n",
        "                    if 'court_detector' in globals() and court_detector is not None:\n",
        "                        print(\"üèüÔ∏è Running court detection...\")\n",
        "                        court_keypoints = court_detector.detect_court_in_frame(frame)\n",
        "                        if court_keypoints:\n",
        "                            # Filter out None points\n",
        "                            court_keypoints = [\n",
        "                                (kp[0], kp[1]) if kp and kp[0] is not None and kp[1] is not None else None\n",
        "                                for kp in court_keypoints\n",
        "                            ]\n",
        "                            valid_points = sum(1 for kp in court_keypoints if kp is not None)\n",
        "                            print(f\"‚úÖ Court detected: {valid_points} valid keypoints\")\n",
        "                        else:\n",
        "                            print(\"‚ö†Ô∏è Court detection returned None\")\n",
        "                    else:\n",
        "                        print(\"‚ö†Ô∏è Court detector not available (not initialized in Step 5)\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Court detection error: {e}\")\n",
        "            \n",
        "            # Create frame with skeleton\n",
        "            vis_frame = visualizer.create_frame(\n",
        "                frame=frame,\n",
        "                player_outputs=outputs,\n",
        "                ball_detection=ball_detection,\n",
        "                ball_trajectory=ball_trajectory,\n",
        "                skeleton_visualizer=None,\n",
        "                court_keypoints=court_keypoints\n",
        "            )\n",
        "            \n",
        "            # Add mesh if available and not keypoints_only\n",
        "            total_start = time.time()\n",
        "            \n",
        "            if not keypoints_only and len(outputs) > 0:\n",
        "                try:\n",
        "                    from mesh_visualizer import visualize_sample_together_emerald\n",
        "                    if hasattr(estimator, 'faces') and estimator.faces is not None:\n",
        "                        print(\"üé® Adding 3D mesh...\")\n",
        "                        print(f\"   ‚ö†Ô∏è WARNING: Full mesh rendering takes 2-4 minutes per frame!\")\n",
        "                        print(f\"   This is normal - mesh rendering is very computationally expensive\")\n",
        "                        mesh_start_time = time.time()\n",
        "                        vis_frame_rgb = cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB)\n",
        "                        faces = estimator.faces\n",
        "                        print(f\"   Starting mesh visualization (faces shape: {faces.shape})...\")\n",
        "                        mesh_frame_rgb = visualize_sample_together_emerald(vis_frame_rgb, outputs, faces)\n",
        "                        vis_frame = cv2.cvtColor(mesh_frame_rgb.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
        "                        mesh_time = time.time() - mesh_start_time\n",
        "                        print(f\"‚úÖ Mesh added (took {mesh_time:.1f} seconds = {mesh_time/60:.1f} minutes)\")\n",
        "                    else:\n",
        "                        print(\"‚ö†Ô∏è No faces available in estimator - mesh rendering skipped\")\n",
        "                        print(\"   This means only skeleton will be shown (keypoints-only mode)\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Mesh rendering failed: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "            elif keypoints_only:\n",
        "                print(\"‚ÑπÔ∏è Keypoints-only mode - mesh rendering skipped (faster, ~0.5s/frame)\")\n",
        "            elif len(outputs) == 0:\n",
        "                print(\"‚ÑπÔ∏è No player detections - mesh rendering skipped\")\n",
        "            \n",
        "            total_time = time.time() - total_start\n",
        "            print(f\"\\n‚è±Ô∏è Total processing time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)\")\n",
        "            \n",
        "            # Upscale back to original if we downscaled\n",
        "            if scale_factor < 1.0:\n",
        "                vis_frame = cv2.resize(vis_frame, (original_width, original_height), interpolation=cv2.INTER_LINEAR)\n",
        "            \n",
        "            # Display result\n",
        "            print(\"\\n‚úÖ Processing complete! Displaying result...\\n\")\n",
        "            \n",
        "            # Convert BGR to RGB for display\n",
        "            vis_frame_rgb = cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # Create figure\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "            \n",
        "            # Original frame\n",
        "            axes[0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            axes[0].set_title(f'Original Frame {test_frame_number}', fontsize=14)\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            # Processed frame\n",
        "            axes[1].imshow(vis_frame_rgb)\n",
        "            axes[1].set_title(f'Processed Frame {test_frame_number} (with mesh, ball, skeleton)', fontsize=14)\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            print(f\"\\nüìä Frame Info:\")\n",
        "            print(f\"   Original size: {original_width}x{original_height}\")\n",
        "            print(f\"   Processed size: {vis_frame.shape[1]}x{vis_frame.shape[0]}\")\n",
        "            print(f\"   Players detected: {len(outputs)}\")\n",
        "            print(f\"   Ball detected: {'Yes' if ball_detection else 'No'}\")\n",
        "            print(f\"   Court detected: {'Yes' if court_keypoints else 'No'}\")\n",
        "            print(f\"   Mesh rendering: {'Yes' if not keypoints_only else 'No (keypoints only)'}\")\n",
        "            print(f\"\\n‚úÖ If this looks good, proceed to Step 7 to process the full video!\")\n",
        "        \n",
        "        cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step7"
      },
      "source": [
        "## Step 7: Process Full Video\n",
        "\n",
        "**‚ö†Ô∏è This will take a long time!**\n",
        "\n",
        "Processing times:\n",
        "- Keypoints-only: ~0.5 seconds per frame\n",
        "- Full mesh at 1080px: ~3-4 minutes per frame\n",
        "- Full mesh at 720px: ~2-3 minutes per frame\n",
        "\n",
        "For a 30fps video (6518 frames):\n",
        "- Keypoints-only: ~54 minutes\n",
        "- Full mesh at 1080px: ~325-434 hours (13-18 days!)\n",
        "- Full mesh at 720px: ~217-326 hours (9-13 days!)\n",
        "\n",
        "**Recommendation:** Use `frame_skip=5` or higher for full mesh to reduce processing time significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process_video"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Ensure paths are defined\n",
        "drive_base = '/content/drive/MyDrive/CourtVision'\n",
        "hero_video_path = f\"{drive_base}/hero-video\"\n",
        "\n",
        "# Check that required variables exist\n",
        "if 'input_video_path' not in globals() or input_video_path is None:\n",
        "    print(\"‚ùå Error: Video file not found. Please run Step 4 first.\")\n",
        "elif 'config' not in globals():\n",
        "    print(\"‚ùå Error: Configuration not set. Please run Step 6 first.\")\n",
        "else:\n",
        "    # Find processing script\n",
        "    hero_video_script = f\"{hero_video_path}/process_hero_video.py\"\n",
        "\n",
        "    if not os.path.exists(hero_video_script):\n",
        "        print(f\"‚ùå Script not found: {hero_video_script}\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Found script: {hero_video_script}\")\n",
        "        print(\"\\nüöÄ Processing video...\")\n",
        "        \n",
        "        script_dir = os.path.dirname(hero_video_script)\n",
        "        \n",
        "        cmd = [\n",
        "            sys.executable, hero_video_script,\n",
        "            \"--input\", input_video_path,\n",
        "            \"--output\", \"/content/output/hero_video_processed.mp4\",\n",
        "            \"--frame-skip\", str(config['frame_skip']),\n",
        "            \"--fps\", str(config['fps']),\n",
        "            \"--player-color\", config['player_color'],\n",
        "            \"--ball-color\", config['ball_color'],\n",
        "            \"--trail-length\", str(config['trail_length']),\n",
        "        ]\n",
        "        \n",
        "        if config['keypoints_only']:\n",
        "            cmd.append(\"--keypoints-only\")\n",
        "        \n",
        "        if config['process_resolution'] > 0:\n",
        "            cmd.extend([\"--process-resolution\", str(config['process_resolution'])])\n",
        "        \n",
        "        if config['enable_court_detection']:\n",
        "            cmd.append(\"--enable-court-detection\")\n",
        "        \n",
        "        if config['use_ensemble_ball']:\n",
        "            cmd.append(\"--ensemble-ball\")\n",
        "        \n",
        "        print(\"Command:\")\n",
        "        print(\" \".join(cmd))\n",
        "        print(\"\\n‚è≥ Processing (this will take a while)...\")\n",
        "        print(\"üìä Debug output will stream below in real-time:\\n\")\n",
        "        \n",
        "        import time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Run subprocess with real-time output streaming\n",
        "        process = subprocess.Popen(\n",
        "            cmd,\n",
        "            cwd=script_dir,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,  # Combine stderr into stdout\n",
        "            text=True,\n",
        "            bufsize=1,  # Line buffered\n",
        "            universal_newlines=True\n",
        "        )\n",
        "        \n",
        "        # Stream output in real-time\n",
        "        output_lines = []\n",
        "        for line in process.stdout:\n",
        "            print(line, end='')  # Print immediately\n",
        "            output_lines.append(line)\n",
        "            sys.stdout.flush()  # Force flush to show output immediately\n",
        "        \n",
        "        # Wait for process to complete\n",
        "        returncode = process.wait()\n",
        "        end_time = time.time()\n",
        "        \n",
        "        # Get full output\n",
        "        full_output = ''.join(output_lines)\n",
        "        \n",
        "        if returncode == 0:\n",
        "            print(f\"\\n\\n‚úÖ Processing complete!\")\n",
        "            print(f\"‚è±Ô∏è Time: {(end_time - start_time) / 60:.2f} minutes\")\n",
        "            output_video_path = \"/content/output/hero_video_processed.mp4\"\n",
        "        else:\n",
        "            print(f\"\\n\\n‚ùå Processing failed with return code {returncode}\")\n",
        "            print(\"\\nüìã Full output (last 200 lines):\")\n",
        "            output_lines_list = full_output.split('\\n')\n",
        "            for line in output_lines_list[-200:]:\n",
        "                print(line)\n",
        "            output_video_path = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step8"
      },
      "source": [
        "## Step 8: Download Output Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "output_path = \"/content/output/hero_video_processed.mp4\"\n",
        "if os.path.exists(output_path):\n",
        "    print(f\"üì• Downloading {output_path}...\")\n",
        "    files.download(output_path)\n",
        "    print(\"‚úÖ Download complete!\")\n",
        "else:\n",
        "    print(f\"‚ùå Output file not found: {output_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
